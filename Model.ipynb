{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6537086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df0_AAA = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\AAA_normalized1_0.0.csv\")\n",
    "df0_CCC = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\CCC_normalized1_0.0.csv\")\n",
    "df0_DDD = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\DDD_normalized1_0.0.csv\")\n",
    "df0_EEE = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\EEE_normalized1_0.0.csv\")\n",
    "df0_FFF = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\FFF_normalized1_0.0.csv\")\n",
    "df0_GGG = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\GGG_normalized1_0.0.csv\")\n",
    "df0_BBB = pd.read_csv(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\BBB_normalized1_0.0.csv\")\n",
    "df0_ABCD = pd.concat([df0_AAA, df0_BBB, df0_CCC,df0_DDD], axis=0, ignore_index=True)\n",
    "df0_CD= pd.concat([df0_CCC,df0_DDD], axis=0, ignore_index=True)\n",
    "\n",
    "base_path = Path(r\"D:\\myx\\Data science project·\\outputs\\normalized_module_csvs\\fused_scaled\")\n",
    "# 25% \n",
    "df25_AAA = pd.read_csv(base_path / \"AAA_normalized1_fused_scaled.csv\")\n",
    "df25_BBB = pd.read_csv(base_path / \"BBB_normalized1_fused_scaled.csv\")\n",
    "df25_CCC = pd.read_csv(base_path / \"CCC_normalized1_fused_scaled.csv\")\n",
    "df25_DDD = pd.read_csv(base_path / \"DDD_normalized1_fused_scaled.csv\")\n",
    "df25_EEE = pd.read_csv(base_path / \"EEE_normalized1_fused_scaled.csv\")\n",
    "df25_FFF = pd.read_csv(base_path / \"FFF_normalized1_fused_scaled.csv\")\n",
    "df25_GGG = pd.read_csv(base_path / \"GGG_normalized1_fused_scaled.csv\")\n",
    "df25_ABCD = pd.concat([df25_AAA, df25_BBB, df25_CCC, df25_DDD], axis=0, ignore_index=True)\n",
    "df25_CD= pd.concat([df25_CCC,df25_DDD], axis=0, ignore_index=True)\n",
    "# 50% \n",
    "df50_AAA = pd.read_csv(base_path / \"AAA_normalized1_0.5_fused_scaled.csv\")\n",
    "df50_BBB = pd.read_csv(base_path / \"BBB_normalized1_0.5_fused_scaled.csv\")\n",
    "df50_CCC = pd.read_csv(base_path / \"CCC_normalized1_0.5_fused_scaled.csv\")\n",
    "df50_DDD = pd.read_csv(base_path / \"DDD_normalized1_0.5_fused_scaled.csv\")\n",
    "df50_FFF = pd.read_csv(base_path / \"FFF_normalized1_0.5_fused_scaled.csv\")\n",
    "df50_ABCD = pd.concat([df50_AAA, df50_BBB, df50_CCC, df50_DDD], axis=0, ignore_index=True)\n",
    "df50_CD= pd.concat([df50_CCC,df50_DDD], axis=0, ignore_index=True)\n",
    "# 75% \n",
    "df75_AAA = pd.read_csv(base_path / \"AAA_normalized1_0.75_fused_scaled.csv\")\n",
    "df75_BBB = pd.read_csv(base_path / \"BBB_normalized1_0.75_fused_scaled.csv\")\n",
    "df75_CCC = pd.read_csv(base_path / \"CCC_normalized1_0.75_fused_scaled.csv\")\n",
    "df75_DDD = pd.read_csv(base_path / \"DDD_normalized1_0.75_fused_scaled.csv\")\n",
    "df75_FFF = pd.read_csv(base_path / \"FFF_normalized1_0.75_fused_scaled.csv\")\n",
    "df75_ABCD = pd.concat([df75_AAA, df75_BBB, df75_CCC, df75_DDD], axis=0, ignore_index=True)\n",
    "df75_CD= pd.concat([df75_CCC,df75_DDD], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cec2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result  Distinction  Fail  Pass  Withdrawn\n",
      "code_module                                     \n",
      "AAA                    44    81   486         74\n",
      "BBB                   677  1421  3064        613\n",
      "CCC                   498   662  1175        646\n",
      "DDD                   382  1184  2217        870\n",
      "EEE                   356   401  1288        199\n",
      "FFF                   670  1457  2975        841\n",
      "GGG                   263   289   730         63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"D:\\myx\\Data science project·\\rq1_df1.csv\")\n",
    "\n",
    "result_distribution = df.groupby('code_module')['final_result'].value_counts().unstack().fillna(0).astype(int)\n",
    "\n",
    "print(result_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f6ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df, classification_mode='multi'):\n",
    "    \n",
    "    # drop_ivs = ['Unnamed: 0', 'code_module', 'code_presentation', 'id_student',\n",
    "    #             'final_result', 'date_registration', 'date_unregistration','region']\n",
    "\n",
    "    drop_ivs = ['Unnamed: 0', 'code_module', 'code_presentation', 'id_student',\n",
    "                'final_result', 'date_registration', 'date_unregistration']\n",
    "\n",
    "    # drop_VLE_ivs = [\n",
    "    #     'n_days_dataplus', 'n_days_glossary', 'n_days_oucollaborate',\n",
    "    #     'sum_clicks_dataplus', 'sum_clicks_glossary', 'sum_clicks_oucollaborate',\n",
    "    #     'total_n_days', 'total_sum_clicks', 'module_presentation_length',\n",
    "    #     'cutoff_day', 'year', 'semester'\n",
    "    # ]\n",
    "\n",
    "#     drop_VLE_ivs = [\n",
    "#        'n_days_glossary',  'n_days_oucollaborate',\n",
    "#        'n_days_ouelluminate', \n",
    "#        'n_days_sharedsubpage', \n",
    "#        'n_days_dataplus', 'n_days_dualpane', 'n_days_repeatactivity', \n",
    "#  'n_days_externalquiz', 'n_days_folder', 'n_days_htmlactivity', 'n_days_ouwiki', 'n_days_page', 'n_days_questionnaire',\n",
    "#         'sum_clicks_glossary',  'sum_clicks_dataplus', 'sum_clicks_dualpane', 'sum_clicks_externalquiz', 'sum_clicks_folder',\n",
    "#        'sum_clicks_oucollaborate',  'sum_clicks_htmlactivity',  'sum_clicks_ouwiki', 'sum_clicks_page', 'sum_clicks_questionnaire', \n",
    "#         'sum_clicks_ouelluminate',  \n",
    "#        'sum_clicks_repeatactivity', 'sum_clicks_sharedsubpage', \n",
    "#         'total_n_days',\n",
    "#        'total_sum_clicks', 'module_presentation_length', 'cutoff_day',\n",
    "#        'year', 'semester', 'V_LPB','V_LCB', 'V_KAB', 'V_ILB']\n",
    "\n",
    "    drop_VLE_ivs = [\n",
    "       'n_days_glossary',  'n_days_oucollaborate',\n",
    "       'n_days_ouelluminate', \n",
    "       'n_days_sharedsubpage', \n",
    "       'n_days_dataplus', 'n_days_dualpane', 'n_days_repeatactivity', \n",
    " 'n_days_externalquiz', 'n_days_folder', 'n_days_htmlactivity', 'n_days_ouwiki', 'n_days_page', 'n_days_questionnaire',\n",
    "        'sum_clicks_glossary',  'sum_clicks_dataplus', 'sum_clicks_dualpane', 'sum_clicks_externalquiz', 'sum_clicks_folder',\n",
    "       'sum_clicks_oucollaborate',  'sum_clicks_htmlactivity',  'sum_clicks_ouwiki', 'sum_clicks_page', 'sum_clicks_questionnaire', \n",
    "        'sum_clicks_ouelluminate',  \n",
    "       'sum_clicks_repeatactivity', 'sum_clicks_sharedsubpage', \n",
    "        'total_n_days',\n",
    "       'total_sum_clicks', 'module_presentation_length', 'cutoff_day',\n",
    "       'year', 'semester']\n",
    "\n",
    "\n",
    "    drop_fused_raw = [\n",
    "    'sum_clicks_homepage', 'n_days_homepage',\n",
    "    'sum_clicks_resource', 'n_days_resource',\n",
    "    'sum_clicks_oucontent', 'n_days_oucontent',\n",
    "    'sum_clicks_url', 'n_days_url',\n",
    "    'sum_clicks_forumng', 'n_days_forumng',\n",
    "    'sum_clicks_ouwiki', 'n_days_ouwiki',\n",
    "    'sum_clicks_subpage', 'n_days_subpage',\n",
    "    'sum_clicks_quiz', 'n_days_quiz'\n",
    "]\n",
    "\n",
    "\n",
    "    drop_ivs += drop_VLE_ivs\n",
    "    drop_ivs += drop_fused_raw\n",
    "\n",
    "    if classification_mode == 'multi':\n",
    "        y = df['final_result']\n",
    "    elif classification_mode == 'pass_fail':\n",
    "        y = df['final_result'].replace({0: 0, 1: 0, 2: 1, 3: 1})\n",
    "    elif classification_mode == 'dropout':\n",
    "        y = df['final_result'].replace({1: 1, 0: 0, 2: 0, 3: 0})\n",
    "    elif classification_mode == 'drop_fail_pass':\n",
    "        y = df['final_result'].replace({1: 0, 0: 1, 2: 2, 3: 2})\n",
    "    else:\n",
    "        raise ValueError(\"Invalid classification_mode. Choose from ['multi', 'pass_fail', 'dropout', 'drop_fail_pass']\")\n",
    "\n",
    "    X = df[[col for col in df.columns if col not in drop_ivs]]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def run_model_RF_weighted(df, course_name='RF_AAA', classification_mode='dropout'):\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    import shap\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "    from sklearn.metrics import cohen_kappa_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "    # Train-test split\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=101, stratify=df['final_result'])\n",
    "\n",
    "    X_train, y_train = get_x_y(df_train, classification_mode)\n",
    "    X_test, y_test = get_x_y(df_test, classification_mode)\n",
    "\n",
    "   \n",
    "    # class_weights_options = [\n",
    "    #     None,\n",
    "    #     'balanced',\n",
    "    #     {0: 1, 1: 1.5},\n",
    "    #     {0: 1, 1: 2},\n",
    "    #     {0: 1, 1: 3},\n",
    "    #     {0: 1, 1: 4}\n",
    "    # ]\n",
    "    class_weights_options = [\n",
    "     \n",
    "        'balanced',\n",
    "       \n",
    "    ]\n",
    "    param_grid = {\n",
    "    'n_estimators': [400, 500, 600],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [5, 7],\n",
    "    'min_samples_split': [6, 8, 10, 12],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': [18],\n",
    "    'class_weight': class_weights_options \n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"\\n Performing grid search\")\n",
    "    gs = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_model = gs.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Parameters Found:\")\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    # Prediction on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    # AUC score\n",
    "    classes = np.unique(y_test)\n",
    "    if len(classes) == 2:\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        y_test_bin = label_binarize(y_test, classes=classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    base_wd = os.path.normpath(os.getcwd())\n",
    "    out_dir = os.path.join(base_wd, f\"outputs/models/{course_name}/{classification_mode}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Save model predict\n",
    "    y_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred}).join(X_test)\n",
    "    y_df.to_csv(os.path.join(out_dir, \"rq1_y_predict.csv\"), index=False)\n",
    "\n",
    "    import joblib\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(out_dir, \"rf_model.pkl\")\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    feature_names = list(X_train.columns)\n",
    "    with open(os.path.join(out_dir, \"rf_features.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(feature_names))\n",
    "    print(f\"\\n[INFO] RandomForest model saved to: {model_path}\")\n",
    "\n",
    "    results = {\n",
    "        'f1_score_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'f1_score_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'auc_score': auc,\n",
    "        'kappa_score': cohen_kappa_score(y_test, y_pred),\n",
    "        'mcc_score': matthews_corrcoef(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'importances': {f: imp for f, imp in zip(X_train.columns, best_model.feature_importances_)}\n",
    "    }\n",
    "\n",
    "\n",
    "    pd.DataFrame.from_dict(results.items()).to_csv(os.path.join(out_dir, \"rq1_results.csv\"))\n",
    "\n",
    "    print(f\"\\n[{course_name} - {classification_mode}] Evaluation:\")\n",
    "    print(f\"Macro F1 score:    {results['f1_score_macro']:.4f}\")\n",
    "    print(f\"Weighted F1 score: {results['f1_score_weighted']:.4f}\")\n",
    "    print(f\"Accuracy:          {results['accuracy']:.4f}\")\n",
    "    print(f\"AUC Score:         {results['auc_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for feat, imp in sorted(results['importances'].items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"{feat:<30s}: {imp:.6f}\")\n",
    "\n",
    " \n",
    "    print(\"\\n SHAP values\")\n",
    "    X_sub = shap.utils.sample(X_test, min(1500, len(X_test)), random_state=42)\n",
    "    explainer = shap.Explainer(best_model, X_sub)\n",
    "    shap_values = explainer(X_sub, check_additivity=False)\n",
    "\n",
    "    for class_idx in range(shap_values.values.shape[2]):\n",
    "        shap_class = shap.Explanation(\n",
    "            values=shap_values.values[:, :, class_idx],\n",
    "            base_values=shap_values.base_values[:, class_idx],\n",
    "            data=shap_values.data,\n",
    "            feature_names=shap_values.feature_names,\n",
    "        )\n",
    "        plt.clf()\n",
    "        shap.plots.beeswarm(shap_class, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"beeswarm_class{class_idx}.png\"))\n",
    "\n",
    "    for class_idx in range(min(4, shap_values.values.shape[2])):\n",
    "        shap_single = shap.Explanation(\n",
    "            values=shap_values.values[0, :, class_idx],\n",
    "            base_values=shap_values.base_values[0, class_idx],\n",
    "            data=shap_values.data[0],\n",
    "            feature_names=shap_values.feature_names,\n",
    "        )\n",
    "        plt.clf()\n",
    "        shap.plots.waterfall(shap_single, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"waterfall_sample0_class{class_idx}.png\"))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41528f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 0%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 6, 'n_estimators': 600, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_0_change/dropout\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_0_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5379\n",
      "Weighted F1 score: 0.6611\n",
      "Accuracy:          0.6385\n",
      "AUC Score:         0.5838\n",
      "Confusion Matrix:\n",
      "[[379 160]\n",
      " [ 88  59]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       539\n",
      "           1       0.27      0.40      0.32       147\n",
      "\n",
      "    accuracy                           0.64       686\n",
      "   macro avg       0.54      0.55      0.54       686\n",
      "weighted avg       0.70      0.64      0.66       686\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "imd_band                      : 0.308028\n",
      "region                        : 0.303455\n",
      "highest_education             : 0.156624\n",
      "age_band                      : 0.092305\n",
      "disability                    : 0.072261\n",
      "gender                        : 0.067327\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1357/1372 [01:42<00:01]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 25%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_25_change/dropout\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_25_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.6216\n",
      "Weighted F1 score: 0.7339\n",
      "Accuracy:          0.7086\n",
      "AUC Score:         0.7118\n",
      "Confusion Matrix:\n",
      "[[524 190]\n",
      " [ 67 101]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80       714\n",
      "           1       0.35      0.60      0.44       168\n",
      "\n",
      "    accuracy                           0.71       882\n",
      "   macro avg       0.62      0.67      0.62       882\n",
      "weighted avg       0.78      0.71      0.73       882\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.344739\n",
      "V_LPB                         : 0.132360\n",
      "V_LCB                         : 0.127167\n",
      "V_KAB                         : 0.112855\n",
      "V_ILB                         : 0.106272\n",
      "imd_band                      : 0.052962\n",
      "region                        : 0.047709\n",
      "highest_education             : 0.022039\n",
      "disability                    : 0.021163\n",
      "gender                        : 0.019773\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 1758/1764 [01:55<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 50%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 400, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_50_change/dropout\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_50_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5774\n",
      "Weighted F1 score: 0.7733\n",
      "Accuracy:          0.7433\n",
      "AUC Score:         0.7204\n",
      "Confusion Matrix:\n",
      "[[563 152]\n",
      " [ 59  48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.84       715\n",
      "           1       0.24      0.45      0.31       107\n",
      "\n",
      "    accuracy                           0.74       822\n",
      "   macro avg       0.57      0.62      0.58       822\n",
      "weighted avg       0.82      0.74      0.77       822\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.366565\n",
      "V_LPB                         : 0.127317\n",
      "V_LCB                         : 0.117816\n",
      "V_KAB                         : 0.115211\n",
      "V_ILB                         : 0.092300\n",
      "region                        : 0.055367\n",
      "imd_band                      : 0.048824\n",
      "highest_education             : 0.025494\n",
      "disability                    : 0.023027\n",
      "age_band                      : 0.016314\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1623/1644 [01:18<00:01]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 75%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 400, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_75_change/dropout\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_75_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5478\n",
      "Weighted F1 score: 0.8994\n",
      "Accuracy:          0.8859\n",
      "AUC Score:         0.6460\n",
      "Confusion Matrix:\n",
      "[[660  56]\n",
      " [ 30   8]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       716\n",
      "           1       0.12      0.21      0.16        38\n",
      "\n",
      "    accuracy                           0.89       754\n",
      "   macro avg       0.54      0.57      0.55       754\n",
      "weighted avg       0.91      0.89      0.90       754\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.283813\n",
      "V_LPB                         : 0.140630\n",
      "V_KAB                         : 0.136003\n",
      "V_LCB                         : 0.129647\n",
      "V_ILB                         : 0.123316\n",
      "imd_band                      : 0.063586\n",
      "region                        : 0.053993\n",
      "disability                    : 0.024786\n",
      "highest_education             : 0.020222\n",
      "gender                        : 0.015273\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1494/1508 [01:00<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pass_fail Classification for Stage 0%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_0_change/pass_fail\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_0_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.5781\n",
      "Weighted F1 score: 0.5838\n",
      "Accuracy:          0.5860\n",
      "AUC Score:         0.6142\n",
      "Confusion Matrix:\n",
      "[[154 155]\n",
      " [129 248]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52       309\n",
      "           1       0.62      0.66      0.64       377\n",
      "\n",
      "    accuracy                           0.59       686\n",
      "   macro avg       0.58      0.58      0.58       686\n",
      "weighted avg       0.58      0.59      0.58       686\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "imd_band                      : 0.287873\n",
      "highest_education             : 0.255285\n",
      "region                        : 0.251639\n",
      "age_band                      : 0.085234\n",
      "disability                    : 0.069635\n",
      "gender                        : 0.050335\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1358/1372 [01:14<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pass_fail Classification for Stage 25%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_25_change/pass_fail\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_25_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7433\n",
      "Weighted F1 score: 0.7453\n",
      "Accuracy:          0.7449\n",
      "AUC Score:         0.8161\n",
      "Confusion Matrix:\n",
      "[[294 104]\n",
      " [121 363]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       398\n",
      "           1       0.78      0.75      0.76       484\n",
      "\n",
      "    accuracy                           0.74       882\n",
      "   macro avg       0.74      0.74      0.74       882\n",
      "weighted avg       0.75      0.74      0.75       882\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.495202\n",
      "V_LPB                         : 0.145105\n",
      "V_LCB                         : 0.116659\n",
      "V_ILB                         : 0.104861\n",
      "V_KAB                         : 0.062824\n",
      "highest_education             : 0.034860\n",
      "imd_band                      : 0.017666\n",
      "region                        : 0.012550\n",
      "age_band                      : 0.003680\n",
      "disability                    : 0.003445\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1741/1764 [00:54<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pass_fail Classification for Stage 50%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 500, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_50_change/pass_fail\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_50_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7775\n",
      "Weighted F1 score: 0.7825\n",
      "Accuracy:          0.7810\n",
      "AUC Score:         0.8636\n",
      "Confusion Matrix:\n",
      "[[269  69]\n",
      " [111 373]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       338\n",
      "           1       0.84      0.77      0.81       484\n",
      "\n",
      "    accuracy                           0.78       822\n",
      "   macro avg       0.78      0.78      0.78       822\n",
      "weighted avg       0.79      0.78      0.78       822\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.444195\n",
      "V_LPB                         : 0.165695\n",
      "V_LCB                         : 0.116248\n",
      "V_KAB                         : 0.092811\n",
      "V_ILB                         : 0.090689\n",
      "highest_education             : 0.027418\n",
      "imd_band                      : 0.024969\n",
      "region                        : 0.021655\n",
      "age_band                      : 0.006904\n",
      "gender                        : 0.004886\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1629/1644 [02:40<00:01]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pass_fail Classification for Stage 75%\n",
      "\n",
      " Performing grid search\n",
      "\n",
      "Best Parameters Found:\n",
      "{'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 500, 'random_state': 18}\n",
      "\n",
      "[INFO] RandomForest model saved to: c:\\Users\\zh_ch\\Desktop\\outputs/models/RF_DDD_75_change/pass_fail\\rf_model.pkl\n",
      "\n",
      "[RF_DDD_75_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7858\n",
      "Weighted F1 score: 0.7998\n",
      "Accuracy:          0.7971\n",
      "AUC Score:         0.8800\n",
      "Confusion Matrix:\n",
      "[[214  56]\n",
      " [ 97 387]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       270\n",
      "           1       0.87      0.80      0.83       484\n",
      "\n",
      "    accuracy                           0.80       754\n",
      "   macro avg       0.78      0.80      0.79       754\n",
      "weighted avg       0.81      0.80      0.80       754\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "early_score_mean              : 0.369257\n",
      "V_LPB                         : 0.205117\n",
      "V_LCB                         : 0.132223\n",
      "V_ILB                         : 0.119674\n",
      "V_KAB                         : 0.095837\n",
      "highest_education             : 0.021535\n",
      "imd_band                      : 0.021073\n",
      "region                        : 0.019767\n",
      "gender                        : 0.006962\n",
      "age_band                      : 0.005042\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 1501/1508 [03:06<00:00]        "
     ]
    }
   ],
   "source": [
    "#balanced\n",
    "stage_dict = {\n",
    "    '0': df0_DDD,\n",
    "    '25': df25_DDD,\n",
    "    '50': df50_DDD,\n",
    "    '75': df75_DDD\n",
    "}\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\nDropout Classification for Stage {stage}%\")\n",
    "    run_model_RF_weighted(df, course_name=f\"RF_DDD_{stage}_change\", classification_mode='dropout')\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\npass_fail Classification for Stage {stage}%\")\n",
    "    run_model_RF_weighted(df, course_name=f\"RF_DDD_{stage}_change\", classification_mode='pass_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74c0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_LR_weighted(df, course_name='LR_AAA', classification_mode='dropout'):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import joblib\n",
    "    import shap\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        f1_score, accuracy_score, confusion_matrix, classification_report,\n",
    "        roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "    )\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=101, stratify=df['final_result'])\n",
    "    X_train, y_train = get_x_y(df_train, classification_mode)\n",
    "    X_test, y_test = get_x_y(df_test, classification_mode)\n",
    "\n",
    "    class_weights_options = [\n",
    "        \n",
    "        'balanced'\n",
    "    ]\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['liblinear'], \n",
    "        'class_weight': class_weights_options,\n",
    "        'max_iter': [200]\n",
    "    }\n",
    "\n",
    "    print(\"\\n Performing grid search for Logistic Regression\")\n",
    "    gs = GridSearchCV(LogisticRegression(), param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_model = gs.best_estimator_\n",
    "\n",
    "    print(\"\\n Best Parameters Found:\")\n",
    "    print(gs.best_params_)\n",
    "    print(\"\\n Best Class Weight:\")\n",
    "    print(gs.best_params_['class_weight'])\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    classes = np.unique(y_test)\n",
    "    if len(classes) == 2:\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        y_test_bin = label_binarize(y_test, classes=classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), f\"outputs/models/{course_name}/{classification_mode}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    y_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred}).join(X_test)\n",
    "    y_df.to_csv(os.path.join(out_dir, \"rq1_y_predict.csv\"), index=False)\n",
    "\n",
    "    joblib.dump(best_model, os.path.join(out_dir, \"lr_model.pkl\"))\n",
    "    with open(os.path.join(out_dir, \"lr_features.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(X_train.columns))\n",
    "\n",
    "    results = {\n",
    "        'f1_score_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'f1_score_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'auc_score': auc,\n",
    "        'kappa_score': cohen_kappa_score(y_test, y_pred),\n",
    "        'mcc_score': matthews_corrcoef(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'coefficients': dict(zip(X_train.columns, best_model.coef_[0]))\n",
    "    }\n",
    "\n",
    "    pd.DataFrame.from_dict(results.items()).to_csv(os.path.join(out_dir, \"rq1_results.csv\"))\n",
    "\n",
    "    print(f\"\\n[{course_name} - {classification_mode}] Evaluation:\")\n",
    "    print(f\"Macro F1 score:    {results['f1_score_macro']:.4f}\")\n",
    "    print(f\"Weighted F1 score: {results['f1_score_weighted']:.4f}\")\n",
    "    print(f\"Accuracy:          {results['accuracy']:.4f}\")\n",
    "    print(f\"AUC Score:         {results['auc_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nTop 10 Feature Coefficients:\")\n",
    "    for feat, coef in sorted(results['coefficients'].items(), key=lambda x: abs(x[1]), reverse=True)[:10]:\n",
    "        print(f\"{feat:<30s}: {coef:.6f}\")\n",
    "\n",
    "   \n",
    "    print(\"\\n SHAP values\")\n",
    "    X_sub = shap.utils.sample(X_test, min(1500, len(X_test)), random_state=42)\n",
    "    explainer = shap.Explainer(best_model, X_sub)\n",
    "\n",
    "    shap_values = explainer(X_sub)\n",
    "\n",
    "    shap_dir = os.path.join(out_dir, \"shap\")\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "    \n",
    "    plt.clf()\n",
    "    shap.summary_plot(shap_values, X_sub, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(shap_dir, \"shap_beeswarm.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 0%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_0_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5544\n",
      "Weighted F1 score: 0.6724\n",
      "Accuracy:          0.6501\n",
      "AUC Score:         0.5998\n",
      "Confusion Matrix:\n",
      "[[382 157]\n",
      " [ 83  64]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       539\n",
      "           1       0.29      0.44      0.35       147\n",
      "\n",
      "    accuracy                           0.65       686\n",
      "   macro avg       0.56      0.57      0.55       686\n",
      "weighted avg       0.71      0.65      0.67       686\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "imd_band                      : -0.234305\n",
      "disability                    : 0.225694\n",
      "highest_education             : -0.098988\n",
      "gender                        : -0.091720\n",
      "region                        : 0.032746\n",
      "age_band                      : -0.029522\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "Dropout Classification for Stage 25%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_25_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5682\n",
      "Weighted F1 score: 0.6973\n",
      "Accuracy:          0.6689\n",
      "AUC Score:         0.6466\n",
      "Confusion Matrix:\n",
      "[[508 206]\n",
      " [ 86  82]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78       714\n",
      "           1       0.28      0.49      0.36       168\n",
      "\n",
      "    accuracy                           0.67       882\n",
      "   macro avg       0.57      0.60      0.57       882\n",
      "weighted avg       0.75      0.67      0.70       882\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : -0.448676\n",
      "disability                    : 0.284040\n",
      "V_LPB                         : -0.226223\n",
      "V_LCB                         : -0.212516\n",
      "V_ILB                         : -0.153862\n",
      "region                        : 0.153858\n",
      "V_KAB                         : -0.145056\n",
      "gender                        : -0.134842\n",
      "imd_band                      : -0.093049\n",
      "age_band                      : 0.081444\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "Dropout Classification for Stage 50%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_50_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5501\n",
      "Weighted F1 score: 0.7363\n",
      "Accuracy:          0.6910\n",
      "AUC Score:         0.6663\n",
      "Confusion Matrix:\n",
      "[[514 201]\n",
      " [ 53  54]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80       715\n",
      "           1       0.21      0.50      0.30       107\n",
      "\n",
      "    accuracy                           0.69       822\n",
      "   macro avg       0.56      0.61      0.55       822\n",
      "weighted avg       0.82      0.69      0.74       822\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : -0.561768\n",
      "disability                    : 0.352889\n",
      "region                        : 0.239497\n",
      "V_LPB                         : -0.212274\n",
      "V_LCB                         : -0.177887\n",
      "V_KAB                         : -0.159179\n",
      "age_band                      : 0.138419\n",
      "V_ILB                         : -0.118498\n",
      "highest_education             : 0.087590\n",
      "gender                        : -0.051691\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "Dropout Classification for Stage 75%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_75_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.4803\n",
      "Weighted F1 score: 0.7951\n",
      "Accuracy:          0.7162\n",
      "AUC Score:         0.6311\n",
      "Confusion Matrix:\n",
      "[[524 192]\n",
      " [ 22  16]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83       716\n",
      "           1       0.08      0.42      0.13        38\n",
      "\n",
      "    accuracy                           0.72       754\n",
      "   macro avg       0.52      0.58      0.48       754\n",
      "weighted avg       0.92      0.72      0.80       754\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : -0.457791\n",
      "disability                    : 0.417046\n",
      "V_LPB                         : -0.255732\n",
      "V_KAB                         : -0.248437\n",
      "V_LCB                         : -0.232616\n",
      "highest_education             : 0.148108\n",
      "V_ILB                         : -0.144759\n",
      "region                        : 0.138700\n",
      "age_band                      : -0.110941\n",
      "imd_band                      : -0.105676\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 0%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_0_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.5765\n",
      "Weighted F1 score: 0.5804\n",
      "Accuracy:          0.5802\n",
      "AUC Score:         0.6194\n",
      "Confusion Matrix:\n",
      "[[167 142]\n",
      " [146 231]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54       309\n",
      "           1       0.62      0.61      0.62       377\n",
      "\n",
      "    accuracy                           0.58       686\n",
      "   macro avg       0.58      0.58      0.58       686\n",
      "weighted avg       0.58      0.58      0.58       686\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "highest_education             : 0.898013\n",
      "imd_band                      : 0.620947\n",
      "disability                    : -0.381438\n",
      "age_band                      : 0.291973\n",
      "region                        : -0.035355\n",
      "gender                        : 0.031560\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 25%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_25_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7491\n",
      "Weighted F1 score: 0.7516\n",
      "Accuracy:          0.7517\n",
      "AUC Score:         0.8128\n",
      "Confusion Matrix:\n",
      "[[287 111]\n",
      " [108 376]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72       398\n",
      "           1       0.77      0.78      0.77       484\n",
      "\n",
      "    accuracy                           0.75       882\n",
      "   macro avg       0.75      0.75      0.75       882\n",
      "weighted avg       0.75      0.75      0.75       882\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : 6.442752\n",
      "V_LPB                         : 1.591647\n",
      "highest_education             : 1.170729\n",
      "age_band                      : -0.645374\n",
      "V_LCB                         : 0.609676\n",
      "imd_band                      : 0.387886\n",
      "gender                        : 0.187501\n",
      "disability                    : -0.171587\n",
      "V_ILB                         : 0.166475\n",
      "region                        : -0.102597\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 50%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_50_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7504\n",
      "Weighted F1 score: 0.7559\n",
      "Accuracy:          0.7543\n",
      "AUC Score:         0.8501\n",
      "Confusion Matrix:\n",
      "[[259  79]\n",
      " [123 361]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       338\n",
      "           1       0.82      0.75      0.78       484\n",
      "\n",
      "    accuracy                           0.75       822\n",
      "   macro avg       0.75      0.76      0.75       822\n",
      "weighted avg       0.76      0.75      0.76       822\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : 6.850686\n",
      "V_LPB                         : 1.924715\n",
      "highest_education             : 0.937650\n",
      "age_band                      : -0.752286\n",
      "V_LCB                         : 0.466475\n",
      "V_ILB                         : 0.354604\n",
      "imd_band                      : 0.288780\n",
      "V_KAB                         : 0.207264\n",
      "region                        : -0.179883\n",
      "disability                    : -0.160401\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 75%\n",
      "\n",
      " Performing grid search for Logistic Regression\n",
      "\n",
      " Best Parameters Found:\n",
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 200, 'solver': 'liblinear'}\n",
      "\n",
      " Best Class Weight:\n",
      "balanced\n",
      "\n",
      "[LR_DDD_75_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7665\n",
      "Weighted F1 score: 0.7815\n",
      "Accuracy:          0.7785\n",
      "AUC Score:         0.8600\n",
      "Confusion Matrix:\n",
      "[[208  62]\n",
      " [105 379]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       270\n",
      "           1       0.86      0.78      0.82       484\n",
      "\n",
      "    accuracy                           0.78       754\n",
      "   macro avg       0.76      0.78      0.77       754\n",
      "weighted avg       0.79      0.78      0.78       754\n",
      "\n",
      "\n",
      "Top 10 Feature Coefficients:\n",
      "early_score_mean              : 6.405337\n",
      "V_LPB                         : 2.877163\n",
      "highest_education             : 0.813094\n",
      "V_ILB                         : 0.762021\n",
      "V_LCB                         : 0.445963\n",
      "age_band                      : -0.396421\n",
      "imd_band                      : 0.316245\n",
      "gender                        : 0.257442\n",
      "region                        : -0.131695\n",
      "disability                    : -0.069533\n",
      "\n",
      " SHAP values\n"
     ]
    }
   ],
   "source": [
    "#balanced\n",
    "stage_dict = {\n",
    "    '0': df0_DDD,\n",
    "    '25': df25_DDD,\n",
    "    '50': df50_DDD,\n",
    "    '75': df75_DDD\n",
    "}\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\nDropout Classification for Stage {stage}%\")\n",
    "    run_model_LR_weighted(df, course_name=f\"LR_DDD_{stage}_change\", classification_mode='dropout')\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\npass_fail Classification for Stage {stage}%\")\n",
    "    run_model_LR_weighted(df, course_name=f\"LR_DDD_{stage}_change\", classification_mode='pass_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6058a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_LightGBM_weighted(df, course_name='LGBM_AAA', classification_mode='dropout'):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import joblib\n",
    "    import shap\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import (\n",
    "        f1_score, accuracy_score, confusion_matrix, classification_report,\n",
    "        roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "    )\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=101, stratify=df['final_result'])\n",
    "    X_train, y_train = get_x_y(df_train, classification_mode)\n",
    "    X_test, y_test = get_x_y(df_test, classification_mode)\n",
    "\n",
    "    class_weights_options = [\n",
    "      \n",
    "        'balanced',\n",
    "     ]\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5],\n",
    "        'class_weight': class_weights_options\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "    print(\"\\n grid search for LightGBM\")\n",
    "    gs = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "\n",
    "    print(\"\\n Best Parameters Found:\")\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "    classes = np.unique(y_test)\n",
    "    if len(classes) == 2:\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "    else:\n",
    "        y_test_bin = label_binarize(y_test, classes=classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    out_dir = os.path.join(\"outputs/models\", course_name, classification_mode)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    y_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred}).join(X_test.reset_index(drop=True))\n",
    "    y_df.to_csv(os.path.join(out_dir, \"rq1_y_predict.csv\"), index=False)\n",
    "\n",
    "    joblib.dump(best_model, os.path.join(out_dir, \"lgb_model.pkl\"))\n",
    "    with open(os.path.join(out_dir, \"lgb_features.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(X_train.columns))\n",
    "\n",
    "    results = {\n",
    "        'f1_score_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'f1_score_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'auc_score': auc,\n",
    "        'kappa_score': cohen_kappa_score(y_test, y_pred),\n",
    "        'mcc_score': matthews_corrcoef(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'feature_importance': dict(zip(X_train.columns, best_model.feature_importances_))\n",
    "    }\n",
    "\n",
    "    pd.DataFrame.from_dict(results.items()).to_csv(os.path.join(out_dir, \"rq1_results.csv\"), index=False)\n",
    "\n",
    "    print(f\"\\n[{course_name} - {classification_mode}] Evaluation:\")\n",
    "    print(f\"Macro F1 score:    {results['f1_score_macro']:.4f}\")\n",
    "    print(f\"Weighted F1 score: {results['f1_score_weighted']:.4f}\")\n",
    "    print(f\"Accuracy:          {results['accuracy']:.4f}\")\n",
    "    print(f\"AUC Score:         {results['auc_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nTop 10 Feature Importance:\")\n",
    "    for feat, imp in sorted(results['feature_importance'].items(), key=lambda x: abs(x[1]), reverse=True)[:10]:\n",
    "        print(f\"{feat:<30s}: {imp:.6f}\")\n",
    "\n",
    "    print(\"\\n SHAP values\")\n",
    "    X_sub = shap.utils.sample(X_test, min(1500, len(X_test)), random_state=42)\n",
    "    explainer = shap.Explainer(best_model, X_sub)\n",
    "    shap_values = explainer(X_sub, check_additivity=False)\n",
    "\n",
    "\n",
    "    shap_dir = os.path.join(out_dir, \"shap\")\n",
    "    os.makedirs(shap_dir, exist_ok=True)\n",
    "\n",
    "    plt.clf()\n",
    "    shap.summary_plot(shap_values, X_sub, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(shap_dir, \"shap_beeswarm.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.clf()\n",
    "    shap.plots.bar(shap_values, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(shap_dir, \"shap_bar.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.clf()\n",
    "    idx = 0 \n",
    "    shap.plots.waterfall(shap_values[idx], show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(shap_dir, f\"shap_waterfall_sample{idx}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 0%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 2154\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35\n",
      "[LightGBM] [Info] Number of data points in the train set: 2744, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "[LightGBM_DDD_0_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5006\n",
      "Weighted F1 score: 0.6092\n",
      "Accuracy:          0.5729\n",
      "AUC Score:         0.5599\n",
      "Confusion Matrix:\n",
      "[[327 212]\n",
      " [ 81  66]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69       539\n",
      "           1       0.24      0.45      0.31       147\n",
      "\n",
      "    accuracy                           0.57       686\n",
      "   macro avg       0.52      0.53      0.50       686\n",
      "weighted avg       0.68      0.57      0.61       686\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "region                        : 1302.000000\n",
      "imd_band                      : 1268.000000\n",
      "highest_education             : 568.000000\n",
      "gender                        : 326.000000\n",
      "age_band                      : 323.000000\n",
      "disability                    : 157.000000\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 672/686 [00:13<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 25%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 670, number of negative: 2855\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 3525, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "[LightGBM_DDD_25_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.6145\n",
      "Weighted F1 score: 0.7533\n",
      "Accuracy:          0.7449\n",
      "AUC Score:         0.7009\n",
      "Confusion Matrix:\n",
      "[[585 129]\n",
      " [ 96  72]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       714\n",
      "           1       0.36      0.43      0.39       168\n",
      "\n",
      "    accuracy                           0.74       882\n",
      "   macro avg       0.61      0.62      0.61       882\n",
      "weighted avg       0.76      0.74      0.75       882\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "V_LPB                         : 636.000000\n",
      "early_score_mean              : 551.000000\n",
      "V_LCB                         : 550.000000\n",
      "V_KAB                         : 494.000000\n",
      "V_ILB                         : 485.000000\n",
      "region                        : 245.000000\n",
      "imd_band                      : 237.000000\n",
      "highest_education             : 117.000000\n",
      "gender                        : 75.000000\n",
      "disability                    : 61.000000\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 859/882 [00:13<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 50%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 425, number of negative: 2862\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1304\n",
      "[LightGBM] [Info] Number of data points in the train set: 3287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "[LightGBM_DDD_50_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.6135\n",
      "Weighted F1 score: 0.8110\n",
      "Accuracy:          0.7981\n",
      "AUC Score:         0.7288\n",
      "Confusion Matrix:\n",
      "[[612 103]\n",
      " [ 63  44]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       715\n",
      "           1       0.30      0.41      0.35       107\n",
      "\n",
      "    accuracy                           0.80       822\n",
      "   macro avg       0.60      0.63      0.61       822\n",
      "weighted avg       0.83      0.80      0.81       822\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "early_score_mean              : 703.000000\n",
      "V_KAB                         : 588.000000\n",
      "V_LPB                         : 586.000000\n",
      "V_ILB                         : 531.000000\n",
      "V_LCB                         : 513.000000\n",
      "imd_band                      : 239.000000\n",
      "region                        : 216.000000\n",
      "highest_education             : 82.000000\n",
      "gender                        : 69.000000\n",
      "disability                    : 44.000000\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 794/822 [00:13<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dropout Classification for Stage 75%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 151, number of negative: 2864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 3015, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "[LightGBM_DDD_75_change - dropout] Evaluation:\n",
      "Macro F1 score:    0.5534\n",
      "Weighted F1 score: 0.9188\n",
      "Accuracy:          0.9231\n",
      "AUC Score:         0.6285\n",
      "Confusion Matrix:\n",
      "[[691  25]\n",
      " [ 33   5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       716\n",
      "           1       0.17      0.13      0.15        38\n",
      "\n",
      "    accuracy                           0.92       754\n",
      "   macro avg       0.56      0.55      0.55       754\n",
      "weighted avg       0.91      0.92      0.92       754\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "early_score_mean              : 700.000000\n",
      "V_LPB                         : 604.000000\n",
      "V_ILB                         : 594.000000\n",
      "V_KAB                         : 552.000000\n",
      "V_LCB                         : 488.000000\n",
      "imd_band                      : 252.000000\n",
      "region                        : 227.000000\n",
      "disability                    : 72.000000\n",
      "highest_education             : 68.000000\n",
      "gender                        : 58.000000\n",
      "\n",
      " SHAP values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|=================== | 707/754 [00:11<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "pass_fail Classification for Stage 0%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 1507, number of negative: 1237\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35\n",
      "[LightGBM] [Info] Number of data points in the train set: 2744, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "[LightGBM_DDD_0_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.5984\n",
      "Weighted F1 score: 0.6022\n",
      "Accuracy:          0.6020\n",
      "AUC Score:         0.6227\n",
      "Confusion Matrix:\n",
      "[[174 135]\n",
      " [138 239]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       309\n",
      "           1       0.64      0.63      0.64       377\n",
      "\n",
      "    accuracy                           0.60       686\n",
      "   macro avg       0.60      0.60      0.60       686\n",
      "weighted avg       0.60      0.60      0.60       686\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "region                        : 222.000000\n",
      "imd_band                      : 193.000000\n",
      "age_band                      : 85.000000\n",
      "highest_education             : 73.000000\n",
      "disability                    : 54.000000\n",
      "gender                        : 29.000000\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 25%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 1933, number of negative: 1592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1291\n",
      "[LightGBM] [Info] Number of data points in the train set: 3525, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "[LightGBM_DDD_25_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7486\n",
      "Weighted F1 score: 0.7508\n",
      "Accuracy:          0.7506\n",
      "AUC Score:         0.8231\n",
      "Confusion Matrix:\n",
      "[[292 106]\n",
      " [114 370]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       398\n",
      "           1       0.78      0.76      0.77       484\n",
      "\n",
      "    accuracy                           0.75       882\n",
      "   macro avg       0.75      0.75      0.75       882\n",
      "weighted avg       0.75      0.75      0.75       882\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "early_score_mean              : 208.000000\n",
      "V_LPB                         : 118.000000\n",
      "V_LCB                         : 70.000000\n",
      "V_ILB                         : 69.000000\n",
      "highest_education             : 47.000000\n",
      "V_KAB                         : 44.000000\n",
      "imd_band                      : 43.000000\n",
      "region                        : 31.000000\n",
      "age_band                      : 24.000000\n",
      "gender                        : 12.000000\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 50%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 1937, number of negative: 1350\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1304\n",
      "[LightGBM] [Info] Number of data points in the train set: 3287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "[LightGBM_DDD_50_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7799\n",
      "Weighted F1 score: 0.7849\n",
      "Accuracy:          0.7835\n",
      "AUC Score:         0.8619\n",
      "Confusion Matrix:\n",
      "[[270  68]\n",
      " [110 374]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75       338\n",
      "           1       0.85      0.77      0.81       484\n",
      "\n",
      "    accuracy                           0.78       822\n",
      "   macro avg       0.78      0.79      0.78       822\n",
      "weighted avg       0.79      0.78      0.78       822\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "early_score_mean              : 238.000000\n",
      "V_LPB                         : 119.000000\n",
      "V_KAB                         : 75.000000\n",
      "V_LCB                         : 60.000000\n",
      "V_ILB                         : 50.000000\n",
      "region                        : 49.000000\n",
      "highest_education             : 43.000000\n",
      "imd_band                      : 27.000000\n",
      "age_band                      : 18.000000\n",
      "disability                    : 9.000000\n",
      "\n",
      " SHAP values\n",
      "\n",
      "\n",
      "pass_fail Classification for Stage 75%\n",
      "\n",
      " grid search for LightGBM\n",
      "[LightGBM] [Info] Number of positive: 1938, number of negative: 1077\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1310\n",
      "[LightGBM] [Info] Number of data points in the train set: 3015, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Best Parameters Found:\n",
      "{'class_weight': 'balanced', 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "[LightGBM_DDD_75_change - pass_fail] Evaluation:\n",
      "Macro F1 score:    0.7785\n",
      "Weighted F1 score: 0.7923\n",
      "Accuracy:          0.7891\n",
      "AUC Score:         0.8750\n",
      "Confusion Matrix:\n",
      "[[215  55]\n",
      " [104 380]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       270\n",
      "           1       0.87      0.79      0.83       484\n",
      "\n",
      "    accuracy                           0.79       754\n",
      "   macro avg       0.77      0.79      0.78       754\n",
      "weighted avg       0.80      0.79      0.79       754\n",
      "\n",
      "\n",
      "Top 10 Feature Importance:\n",
      "early_score_mean              : 191.000000\n",
      "V_LPB                         : 149.000000\n",
      "V_ILB                         : 89.000000\n",
      "V_KAB                         : 72.000000\n",
      "V_LCB                         : 71.000000\n",
      "highest_education             : 41.000000\n",
      "imd_band                      : 28.000000\n",
      "gender                        : 16.000000\n",
      "region                        : 13.000000\n",
      "age_band                      : 1.000000\n",
      "\n",
      " SHAP values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#balanced\n",
    "stage_dict = {\n",
    "    '0': df0_DDD,\n",
    "    '25': df25_DDD,\n",
    "    '50': df50_DDD,\n",
    "    '75': df75_DDD\n",
    "}\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\nDropout Classification for Stage {stage}%\")\n",
    "    run_model_LightGBM_weighted(df, course_name=f\"LightGBM_DDD_{stage}_change\", classification_mode='dropout')\n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    print(f\"\\n\\npass_fail Classification for Stage {stage}%\")\n",
    "    run_model_LightGBM_weighted(df, course_name=f\"LightGBM_DDD_{stage}_change\", classification_mode='pass_fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95ec9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_DFFNN_weighted(df,\n",
    "                              course_name='DFFNN_AAA',\n",
    "                              classification_mode='dropout',\n",
    "                              class_weight_option=None \n",
    "                             ):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import joblib\n",
    "    import shap\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import (\n",
    "        f1_score, accuracy_score, confusion_matrix, classification_report,\n",
    "        roc_auc_score, cohen_kappa_score, matthews_corrcoef\n",
    "    )\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    def prepare_dffnn_data(df, classification_mode):\n",
    "        X, y = get_x_y(df, classification_mode)\n",
    "        feature_names = X.columns.tolist()\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        y_encoded = y.values.reshape(-1, 1)\n",
    "        return X_scaled, y_encoded, feature_names, np.unique(y)\n",
    "\n",
    "    def build_dffnn(input_dim, output_dim=1):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(output_dim, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=101, stratify=df['final_result'])\n",
    "    X_train, y_train, feature_names, class_names = prepare_dffnn_data(df_train, classification_mode)\n",
    "    X_test, y_test, _, _ = prepare_dffnn_data(df_test, classification_mode)\n",
    "\n",
    "    if class_weight_option is None:\n",
    "        class_weight_dict = None\n",
    "    elif class_weight_option == 'balanced':\n",
    "        class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train.flatten()), y=y_train.flatten())\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "    elif isinstance(class_weight_option, dict):\n",
    "        class_weight_dict = class_weight_option\n",
    "    else:\n",
    "        raise ValueError(\"Error\")\n",
    "\n",
    "    model = build_dffnn(input_dim=X_train.shape[1])\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "              validation_split=0.1, callbacks=[es], verbose=1,\n",
    "              class_weight=class_weight_dict)\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    y_pred_label = (y_pred > 0.5).astype(int)\n",
    "    y_true_label = y_test.flatten()\n",
    "\n",
    "    auc = roc_auc_score(y_true_label, y_pred)\n",
    "    results = {\n",
    "        'f1_score_macro': f1_score(y_true_label, y_pred_label, average='macro'),\n",
    "        'f1_score_weighted': f1_score(y_true_label, y_pred_label, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_true_label, y_pred_label),\n",
    "        'auc_score': auc,\n",
    "        'confusion_matrix': confusion_matrix(y_true_label, y_pred_label)\n",
    "    }\n",
    "\n",
    "    out_dir = os.path.join(\"outputs/models\", course_name, classification_mode)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    pd.DataFrame({'y_true': y_true_label, 'y_pred': y_pred_label}).to_csv(os.path.join(out_dir, \"dffnn_predictions.csv\"), index=False)\n",
    "    pd.DataFrame.from_dict(results.items()).to_csv(os.path.join(out_dir, \"dffnn_results.csv\"))\n",
    "    model.save(os.path.join(out_dir, \"dffnn_model.h5\"))\n",
    "    with open(os.path.join(out_dir, \"dffnn_features.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(feature_names))\n",
    "\n",
    "    print(f\"\\n[{course_name} - {classification_mode}] Evaluation:\")\n",
    "    print(f\"Macro F1 score:    {results['f1_score_macro']:.4f}\")\n",
    "    print(f\"Weighted F1 score: {results['f1_score_weighted']:.4f}\")\n",
    "    print(f\"Accuracy:          {results['accuracy']:.4f}\")\n",
    "    print(f\"AUC Score:         {results['auc_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true_label, y_pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23647a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stage 0%  Weight: balanced =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\text_analytics\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4063 - loss: 0.6973 - val_accuracy: 0.6945 - val_loss: 0.6619\n",
      "Epoch 2/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6303 - loss: 0.6894 - val_accuracy: 0.5673 - val_loss: 0.6909\n",
      "Epoch 3/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5931 - loss: 0.6838 - val_accuracy: 0.6364 - val_loss: 0.6699\n",
      "Epoch 4/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5167 - loss: 0.6873 - val_accuracy: 0.6545 - val_loss: 0.6552\n",
      "Epoch 5/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 0.6794 - val_accuracy: 0.5782 - val_loss: 0.6888\n",
      "Epoch 6/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6350 - loss: 0.6812 - val_accuracy: 0.6109 - val_loss: 0.6811\n",
      "Epoch 7/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5961 - loss: 0.6703 - val_accuracy: 0.6364 - val_loss: 0.6670\n",
      "Epoch 8/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5736 - loss: 0.7006 - val_accuracy: 0.5927 - val_loss: 0.6847\n",
      "Epoch 9/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5869 - loss: 0.6794 - val_accuracy: 0.6182 - val_loss: 0.6788\n",
      "Epoch 10/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5371 - loss: 0.7011 - val_accuracy: 0.6327 - val_loss: 0.6669\n",
      "Epoch 11/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6234 - loss: 0.6877 - val_accuracy: 0.5673 - val_loss: 0.6943\n",
      "Epoch 12/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5521 - loss: 0.6706 - val_accuracy: 0.6036 - val_loss: 0.6838\n",
      "Epoch 13/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5780 - loss: 0.6788 - val_accuracy: 0.6473 - val_loss: 0.6578\n",
      "Epoch 14/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6376 - loss: 0.6712 - val_accuracy: 0.6073 - val_loss: 0.6722\n",
      "Epoch 15/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6083 - loss: 0.6798 - val_accuracy: 0.6036 - val_loss: 0.6750\n",
      "Epoch 16/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6223 - loss: 0.6776 - val_accuracy: 0.6255 - val_loss: 0.6681\n",
      "Epoch 17/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 0.6902 - val_accuracy: 0.6364 - val_loss: 0.6567\n",
      "Epoch 18/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6085 - loss: 0.6789 - val_accuracy: 0.6291 - val_loss: 0.6666\n",
      "Epoch 19/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6229 - loss: 0.6846 - val_accuracy: 0.6182 - val_loss: 0.6694\n",
      "Epoch 20/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6062 - loss: 0.6830 - val_accuracy: 0.6436 - val_loss: 0.6568\n",
      "Epoch 21/200\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6385 - loss: 0.6884 - val_accuracy: 0.6545 - val_loss: 0.6527\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DFFNN_DDD_0_balanced - dropout] Evaluation:\n",
      "Macro F1 score:    0.5534\n",
      "Weighted F1 score: 0.7052\n",
      "Accuracy:          0.7114\n",
      "AUC Score:         0.5939\n",
      "Confusion Matrix:\n",
      "[[448  91]\n",
      " [107  40]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       539\n",
      "           1       0.31      0.27      0.29       147\n",
      "\n",
      "    accuracy                           0.71       686\n",
      "   macro avg       0.56      0.55      0.55       686\n",
      "weighted avg       0.70      0.71      0.71       686\n",
      "\n",
      "\n",
      " Stage 25%  Weight: balanced =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\text_analytics\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6495 - loss: 0.6881 - val_accuracy: 0.7224 - val_loss: 0.6440\n",
      "Epoch 2/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6509 - loss: 0.6671 - val_accuracy: 0.7847 - val_loss: 0.5751\n",
      "Epoch 3/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6908 - loss: 0.6628 - val_accuracy: 0.7139 - val_loss: 0.5963\n",
      "Epoch 4/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6362 - loss: 0.6620 - val_accuracy: 0.6119 - val_loss: 0.6513\n",
      "Epoch 5/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6497 - loss: 0.6388 - val_accuracy: 0.6176 - val_loss: 0.6404\n",
      "Epoch 6/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6335 - loss: 0.6442 - val_accuracy: 0.6771 - val_loss: 0.6107\n",
      "Epoch 7/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6414 - loss: 0.6271 - val_accuracy: 0.7252 - val_loss: 0.5907\n",
      "Epoch 8/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6603 - loss: 0.6334 - val_accuracy: 0.7110 - val_loss: 0.5935\n",
      "Epoch 9/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6431 - loss: 0.6392 - val_accuracy: 0.7422 - val_loss: 0.5615\n",
      "Epoch 10/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6702 - loss: 0.6287 - val_accuracy: 0.6969 - val_loss: 0.5969\n",
      "Epoch 11/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6741 - loss: 0.6231 - val_accuracy: 0.6912 - val_loss: 0.5915\n",
      "Epoch 12/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6500 - loss: 0.6302 - val_accuracy: 0.6629 - val_loss: 0.6195\n",
      "Epoch 13/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6394 - loss: 0.6297 - val_accuracy: 0.5921 - val_loss: 0.6698\n",
      "Epoch 14/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6045 - loss: 0.6366 - val_accuracy: 0.6147 - val_loss: 0.6487\n",
      "Epoch 15/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6319 - loss: 0.6201 - val_accuracy: 0.5099 - val_loss: 0.7204\n",
      "Epoch 16/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6372 - loss: 0.6168 - val_accuracy: 0.6346 - val_loss: 0.6373\n",
      "Epoch 17/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6707 - loss: 0.6238 - val_accuracy: 0.6997 - val_loss: 0.5825\n",
      "Epoch 18/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6823 - loss: 0.6073 - val_accuracy: 0.6969 - val_loss: 0.5954\n",
      "Epoch 19/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6710 - loss: 0.6211 - val_accuracy: 0.7054 - val_loss: 0.5997\n",
      "Epoch 20/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6832 - loss: 0.6175 - val_accuracy: 0.6147 - val_loss: 0.6492\n",
      "Epoch 21/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6716 - loss: 0.6073 - val_accuracy: 0.7139 - val_loss: 0.5809\n",
      "Epoch 22/200\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6824 - loss: 0.6084 - val_accuracy: 0.7082 - val_loss: 0.5835\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "d:\\anaconda\\envs\\text_analytics\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DFFNN_DDD_25_balanced - dropout] Evaluation:\n",
      "Macro F1 score:    0.5841\n",
      "Weighted F1 score: 0.7546\n",
      "Accuracy:          0.7664\n",
      "AUC Score:         0.6487\n",
      "Confusion Matrix:\n",
      "[[630  84]\n",
      " [122  46]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       714\n",
      "           1       0.35      0.27      0.31       168\n",
      "\n",
      "    accuracy                           0.77       882\n",
      "   macro avg       0.60      0.58      0.58       882\n",
      "weighted avg       0.75      0.77      0.75       882\n",
      "\n",
      "\n",
      " Stage 50%  Weight: balanced =\n",
      "Epoch 1/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6189 - loss: 0.6738 - val_accuracy: 0.5258 - val_loss: 0.7068\n",
      "Epoch 2/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5890 - loss: 0.6718 - val_accuracy: 0.7295 - val_loss: 0.6095\n",
      "Epoch 3/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5761 - loss: 0.6638 - val_accuracy: 0.8085 - val_loss: 0.5382\n",
      "Epoch 4/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6756 - loss: 0.6419 - val_accuracy: 0.7082 - val_loss: 0.6085\n",
      "Epoch 5/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6423 - loss: 0.6613 - val_accuracy: 0.8085 - val_loss: 0.5337\n",
      "Epoch 6/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6653 - loss: 0.6654 - val_accuracy: 0.7872 - val_loss: 0.5449\n",
      "Epoch 7/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6982 - loss: 0.6401 - val_accuracy: 0.7082 - val_loss: 0.6112\n",
      "Epoch 8/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6303 - loss: 0.6316 - val_accuracy: 0.7264 - val_loss: 0.5870\n",
      "Epoch 9/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6509 - loss: 0.6292 - val_accuracy: 0.6778 - val_loss: 0.6135\n",
      "Epoch 10/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6652 - loss: 0.6301 - val_accuracy: 0.7477 - val_loss: 0.5671\n",
      "Epoch 11/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6673 - loss: 0.6461 - val_accuracy: 0.7234 - val_loss: 0.5821\n",
      "Epoch 12/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6474 - loss: 0.6253 - val_accuracy: 0.7690 - val_loss: 0.5457\n",
      "Epoch 13/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6754 - loss: 0.6463 - val_accuracy: 0.7690 - val_loss: 0.5401\n",
      "Epoch 14/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6408 - loss: 0.6332 - val_accuracy: 0.7143 - val_loss: 0.5848\n",
      "Epoch 15/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6588 - loss: 0.6308 - val_accuracy: 0.7812 - val_loss: 0.5221\n",
      "Epoch 16/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6554 - loss: 0.6207 - val_accuracy: 0.7143 - val_loss: 0.5672\n",
      "Epoch 17/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6636 - loss: 0.6058 - val_accuracy: 0.6930 - val_loss: 0.5938\n",
      "Epoch 18/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6600 - loss: 0.6098 - val_accuracy: 0.6900 - val_loss: 0.5978\n",
      "Epoch 19/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6846 - loss: 0.6091 - val_accuracy: 0.7082 - val_loss: 0.5783\n",
      "Epoch 20/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6839 - loss: 0.6103 - val_accuracy: 0.7933 - val_loss: 0.4876\n",
      "Epoch 21/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6936 - loss: 0.6292 - val_accuracy: 0.7021 - val_loss: 0.5811\n",
      "Epoch 22/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6710 - loss: 0.6445 - val_accuracy: 0.8237 - val_loss: 0.4445\n",
      "Epoch 23/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.6470 - val_accuracy: 0.7872 - val_loss: 0.5008\n",
      "Epoch 24/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6834 - loss: 0.6098 - val_accuracy: 0.7751 - val_loss: 0.5129\n",
      "Epoch 25/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6691 - loss: 0.6436 - val_accuracy: 0.7690 - val_loss: 0.5317\n",
      "Epoch 26/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6909 - loss: 0.6003 - val_accuracy: 0.7660 - val_loss: 0.5237\n",
      "Epoch 27/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7009 - loss: 0.6050 - val_accuracy: 0.7021 - val_loss: 0.5811\n",
      "Epoch 28/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6693 - loss: 0.6083 - val_accuracy: 0.7021 - val_loss: 0.5849\n",
      "Epoch 29/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6648 - loss: 0.6329 - val_accuracy: 0.6930 - val_loss: 0.6024\n",
      "Epoch 30/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6604 - loss: 0.6216 - val_accuracy: 0.7751 - val_loss: 0.5106\n",
      "Epoch 31/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6950 - loss: 0.5856 - val_accuracy: 0.7356 - val_loss: 0.5517\n",
      "Epoch 32/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6721 - loss: 0.6113 - val_accuracy: 0.7447 - val_loss: 0.5312\n",
      "Epoch 33/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6951 - loss: 0.6102 - val_accuracy: 0.7204 - val_loss: 0.5616\n",
      "Epoch 34/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6829 - loss: 0.6096 - val_accuracy: 0.6687 - val_loss: 0.6237\n",
      "Epoch 35/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.5826 - val_accuracy: 0.6778 - val_loss: 0.6063\n",
      "Epoch 36/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6902 - loss: 0.5998 - val_accuracy: 0.7264 - val_loss: 0.5721\n",
      "Epoch 37/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6714 - loss: 0.6116 - val_accuracy: 0.7933 - val_loss: 0.4798\n",
      "Epoch 38/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7077 - loss: 0.6021 - val_accuracy: 0.7720 - val_loss: 0.4874\n",
      "Epoch 39/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7234 - loss: 0.5763 - val_accuracy: 0.6869 - val_loss: 0.5696\n",
      "Epoch 40/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.5860 - val_accuracy: 0.6717 - val_loss: 0.5874\n",
      "Epoch 41/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6508 - loss: 0.6155 - val_accuracy: 0.7143 - val_loss: 0.5483\n",
      "Epoch 42/200\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 0.5879 - val_accuracy: 0.7447 - val_loss: 0.5322\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DFFNN_DDD_50_balanced - dropout] Evaluation:\n",
      "Macro F1 score:    0.5627\n",
      "Weighted F1 score: 0.7590\n",
      "Accuracy:          0.7238\n",
      "AUC Score:         0.6970\n",
      "Confusion Matrix:\n",
      "[[547 168]\n",
      " [ 59  48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       715\n",
      "           1       0.22      0.45      0.30       107\n",
      "\n",
      "    accuracy                           0.72       822\n",
      "   macro avg       0.56      0.61      0.56       822\n",
      "weighted avg       0.81      0.72      0.76       822\n",
      "\n",
      "\n",
      " Stage 75%  Weight: balanced =\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\text_analytics\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.6827 - val_accuracy: 0.7185 - val_loss: 0.6485\n",
      "Epoch 2/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.6437 - val_accuracy: 0.5563 - val_loss: 0.6780\n",
      "Epoch 3/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6871 - loss: 0.6408 - val_accuracy: 0.6391 - val_loss: 0.6489\n",
      "Epoch 4/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6582 - loss: 0.6579 - val_accuracy: 0.6358 - val_loss: 0.6469\n",
      "Epoch 5/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6663 - loss: 0.6280 - val_accuracy: 0.6755 - val_loss: 0.6080\n",
      "Epoch 6/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6574 - loss: 0.6250 - val_accuracy: 0.7450 - val_loss: 0.5473\n",
      "Epoch 7/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.6633 - val_accuracy: 0.7781 - val_loss: 0.5110\n",
      "Epoch 8/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7190 - loss: 0.6413 - val_accuracy: 0.6623 - val_loss: 0.6221\n",
      "Epoch 9/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6217 - loss: 0.6494 - val_accuracy: 0.6556 - val_loss: 0.6059\n",
      "Epoch 10/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6447 - loss: 0.6705 - val_accuracy: 0.6556 - val_loss: 0.6010\n",
      "Epoch 11/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.6262 - val_accuracy: 0.7185 - val_loss: 0.5466\n",
      "Epoch 12/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6820 - loss: 0.5903 - val_accuracy: 0.6192 - val_loss: 0.6371\n",
      "Epoch 13/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5965 - loss: 0.6317 - val_accuracy: 0.6258 - val_loss: 0.6607\n",
      "Epoch 14/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 0.6048 - val_accuracy: 0.6291 - val_loss: 0.6182\n",
      "Epoch 15/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6698 - loss: 0.5542 - val_accuracy: 0.5795 - val_loss: 0.6604\n",
      "Epoch 16/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.5911 - val_accuracy: 0.6722 - val_loss: 0.5820\n",
      "Epoch 17/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.5702 - val_accuracy: 0.6556 - val_loss: 0.5917\n",
      "Epoch 18/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 0.5861 - val_accuracy: 0.7318 - val_loss: 0.5420\n",
      "Epoch 19/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6797 - loss: 0.6304 - val_accuracy: 0.6026 - val_loss: 0.6426\n",
      "Epoch 20/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.5623 - val_accuracy: 0.5331 - val_loss: 0.7105\n",
      "Epoch 21/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5946 - loss: 0.5971 - val_accuracy: 0.6854 - val_loss: 0.5762\n",
      "Epoch 22/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6723 - loss: 0.5828 - val_accuracy: 0.7583 - val_loss: 0.4934\n",
      "Epoch 23/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 0.5960 - val_accuracy: 0.7417 - val_loss: 0.5371\n",
      "Epoch 24/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6978 - loss: 0.5847 - val_accuracy: 0.6722 - val_loss: 0.5953\n",
      "Epoch 25/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7067 - loss: 0.5766 - val_accuracy: 0.6424 - val_loss: 0.6276\n",
      "Epoch 26/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7105 - loss: 0.5479 - val_accuracy: 0.6490 - val_loss: 0.6202\n",
      "Epoch 27/200\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.5777 - val_accuracy: 0.7219 - val_loss: 0.5440\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DFFNN_DDD_75_balanced - dropout] Evaluation:\n",
      "Macro F1 score:    0.4956\n",
      "Weighted F1 score: 0.8361\n",
      "Accuracy:          0.7798\n",
      "AUC Score:         0.6299\n",
      "Confusion Matrix:\n",
      "[[577 139]\n",
      " [ 27  11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.87       716\n",
      "           1       0.07      0.29      0.12        38\n",
      "\n",
      "    accuracy                           0.78       754\n",
      "   macro avg       0.51      0.55      0.50       754\n",
      "weighted avg       0.91      0.78      0.84       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage_dict = {\n",
    "    '0': df0_DDD,\n",
    "    '25': df25_DDD,\n",
    "    '50': df50_DDD,\n",
    "    '75': df75_DDD\n",
    "}\n",
    "\n",
    "class_weights_options = [\n",
    "  \n",
    "    'balanced',\n",
    "    \n",
    "]\n",
    "\n",
    "classification_mode = 'dropout' \n",
    "\n",
    "for stage, df in stage_dict.items():\n",
    "    for weight in class_weights_options:\n",
    "        print(f\"\\n Stage {stage}%  Weight: {weight} =\")\n",
    "\n",
    "        model_name = f\"DFFNN_DDD_{stage}_balanced\"\n",
    "        \n",
    "        run_model_DFFNN_weighted(\n",
    "            df,\n",
    "            course_name=model_name,\n",
    "            classification_mode=classification_mode,\n",
    "            class_weight_option=weight\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6df0",
   "metadata": {},
   "source": [
    "unseen datasets test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d2a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model_on_unseen(model_path, df_list, stage_list, classification_mode='dropout'):\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    feature_path = os.path.join(os.path.dirname(model_path), \"lgb_features.txt\")  # 改这里\n",
    "    with open(feature_path, \"r\") as f:\n",
    "        trained_features = f.read().splitlines()\n",
    "\n",
    "    for df, stage in zip(df_list, stage_list):\n",
    "        print(f\"\\n Testing on Stage {stage}% \")\n",
    "\n",
    "        X_test, y_test = get_x_y(df, classification_mode)\n",
    "\n",
    "        for feat in trained_features:\n",
    "            if feat not in X_test.columns:\n",
    "                X_test[feat] = 0\n",
    "        X_test = X_test[trained_features]\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "\n",
    "        # AUC\n",
    "        auc = roc_auc_score(y_test, y_proba[:, 1]) if len(model.classes_) == 2 else None\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        if auc:\n",
    "            print(f\"AUC Score: {auc:.4f}\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Running SHAP on Stage {stage}% ...\")\n",
    "            shap_dir = os.path.join(os.path.dirname(model_path), f\"shap_on_C_stage{stage}\")\n",
    "            os.makedirs(shap_dir, exist_ok=True)\n",
    "            X_sub = shap.utils.sample(X_test, min(1500, len(X_test)), random_state=42)\n",
    "            explainer = shap.Explainer(model, X_sub)\n",
    "            shap_values = explainer(X_sub, check_additivity=False)\n",
    "\n",
    "            plt.clf()\n",
    "            shap.summary_plot(shap_values, X_sub, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(shap_dir, \"shap_beeswarm.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            plt.clf()\n",
    "            shap.plots.bar(shap_values, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(shap_dir, \"shap_bar.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            plt.clf()\n",
    "            shap.plots.waterfall(shap_values[0], show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(shap_dir, \"shap_waterfall_sample0.png\"))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"SHAP failed on stage {stage}: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c45cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d751f365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing LightGBM_DDD_0 on Course C \n",
      "\n",
      " Testing on Stage 0% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67      1895\n",
      "           1       0.34      0.41      0.37       839\n",
      "\n",
      "    accuracy                           0.57      2734\n",
      "   macro avg       0.52      0.53      0.52      2734\n",
      "weighted avg       0.60      0.57      0.58      2734\n",
      "\n",
      "AUC Score: 0.5286\n",
      "Running SHAP on Stage 0% ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 1496/1500 [00:13<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing LightGBM_DDD_25 on Course C \n",
      "\n",
      " Testing on Stage 25% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80      2158\n",
      "           1       0.37      0.49      0.42       612\n",
      "\n",
      "    accuracy                           0.70      2770\n",
      "   macro avg       0.61      0.63      0.61      2770\n",
      "weighted avg       0.74      0.70      0.72      2770\n",
      "\n",
      "AUC Score: 0.6874\n",
      "Running SHAP on Stage 25% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_50 on Course C \n",
      "\n",
      " Testing on Stage 50% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      2169\n",
      "           1       0.29      0.34      0.31       334\n",
      "\n",
      "    accuracy                           0.80      2503\n",
      "   macro avg       0.59      0.60      0.60      2503\n",
      "weighted avg       0.81      0.80      0.81      2503\n",
      "\n",
      "AUC Score: 0.6970\n",
      "Running SHAP on Stage 50% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_75 on Course C \n",
      "\n",
      " Testing on Stage 75% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2170\n",
      "           1       0.07      0.05      0.06       103\n",
      "\n",
      "    accuracy                           0.93      2273\n",
      "   macro avg       0.51      0.51      0.51      2273\n",
      "weighted avg       0.92      0.93      0.92      2273\n",
      "\n",
      "AUC Score: 0.6959\n",
      "Running SHAP on Stage 75% ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 1477/1500 [00:11<00:00]       "
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [df0_CCC, df25_CCC, df50_CCC, df75_CCC]\n",
    "stage_list = [0, 25, 50, 75]\n",
    "\n",
    "base_model_name = \"LightGBM_DDD\"\n",
    "classification_mode = \"dropout\"\n",
    "\n",
    "\n",
    "for df, stage in zip(df_list, stage_list):\n",
    "   \n",
    "    model_path = f\"D:/myx/Data science project·/outputs/models/{base_model_name}_{stage}_change/{classification_mode}/lgb_model.pkl\"\n",
    "    print(f\"\\n\\nTesting {base_model_name}_{stage} on Course C \")\n",
    "\n",
    "    test_model_on_unseen(\n",
    "        model_path=model_path,\n",
    "        df_list=[df],        \n",
    "        stage_list=[stage],     \n",
    "        classification_mode=classification_mode\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401375d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing LightGBM_DDD_0 on Course C \n",
      "\n",
      " Testing on Stage 0% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50      1337\n",
      "           1       0.56      0.68      0.62      1397\n",
      "\n",
      "    accuracy                           0.57      2734\n",
      "   macro avg       0.57      0.56      0.56      2734\n",
      "weighted avg       0.57      0.57      0.56      2734\n",
      "\n",
      "AUC Score: 0.5861\n",
      "Running SHAP on Stage 0% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_25 on Course C \n",
      "\n",
      " Testing on Stage 25% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73      1245\n",
      "           1       0.80      0.69      0.74      1525\n",
      "\n",
      "    accuracy                           0.73      2770\n",
      "   macro avg       0.74      0.74      0.73      2770\n",
      "weighted avg       0.74      0.73      0.73      2770\n",
      "\n",
      "AUC Score: 0.8232\n",
      "Running SHAP on Stage 25% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_50 on Course C \n",
      "\n",
      " Testing on Stage 50% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       975\n",
      "           1       0.86      0.75      0.80      1528\n",
      "\n",
      "    accuracy                           0.77      2503\n",
      "   macro avg       0.76      0.78      0.77      2503\n",
      "weighted avg       0.79      0.77      0.77      2503\n",
      "\n",
      "AUC Score: 0.8561\n",
      "Running SHAP on Stage 50% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_75 on Course C \n",
      "\n",
      " Testing on Stage 75% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       744\n",
      "           1       0.92      0.77      0.84      1529\n",
      "\n",
      "    accuracy                           0.80      2273\n",
      "   macro avg       0.78      0.81      0.79      2273\n",
      "weighted avg       0.83      0.80      0.81      2273\n",
      "\n",
      "AUC Score: 0.8918\n",
      "Running SHAP on Stage 75% ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [df0_CCC, df25_CCC, df50_CCC, df75_CCC]\n",
    "stage_list = [0, 25, 50, 75]\n",
    "\n",
    "base_model_name = \"LightGBM_DDD\"\n",
    "classification_mode = \"pass_fail\"\n",
    "\n",
    "\n",
    "for df, stage in zip(df_list, stage_list):\n",
    "   \n",
    "    model_path = f\"D:/myx/Data science project·/outputs/models/{base_model_name}_{stage}_change/{classification_mode}/lgb_model.pkl\"\n",
    "    print(f\"\\n\\nTesting {base_model_name}_{stage} on Course C \")\n",
    "\n",
    "    test_model_on_unseen(\n",
    "        model_path=model_path,\n",
    "        df_list=[df],          \n",
    "        stage_list=[stage],   \n",
    "        classification_mode=classification_mode\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2af7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing LightGBM_DDD_0 on Course F\n",
      "\n",
      " Testing on Stage 0% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.62      0.71      4411\n",
      "           1       0.21      0.46      0.29       972\n",
      "\n",
      "    accuracy                           0.59      5383\n",
      "   macro avg       0.53      0.54      0.50      5383\n",
      "weighted avg       0.73      0.59      0.64      5383\n",
      "\n",
      "AUC Score: 0.5549\n",
      "Running SHAP on Stage 0% ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|=================== | 1421/1500 [00:11<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing LightGBM_DDD_25 on Course F\n",
      "\n",
      " Testing on Stage 25% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      4807\n",
      "           1       0.23      0.32      0.27       804\n",
      "\n",
      "    accuracy                           0.75      5611\n",
      "   macro avg       0.55      0.57      0.56      5611\n",
      "weighted avg       0.79      0.75      0.77      5611\n",
      "\n",
      "AUC Score: 0.6272\n",
      "Running SHAP on Stage 25% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_50 on Course F\n",
      "\n",
      " Testing on Stage 50% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90      4813\n",
      "           1       0.12      0.20      0.15       426\n",
      "\n",
      "    accuracy                           0.82      5239\n",
      "   macro avg       0.52      0.54      0.52      5239\n",
      "weighted avg       0.86      0.82      0.84      5239\n",
      "\n",
      "AUC Score: 0.6059\n",
      "Running SHAP on Stage 50% ...\n",
      "\n",
      "\n",
      "Testing LightGBM_DDD_75 on Course F\n",
      "\n",
      " Testing on Stage 75% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      4814\n",
      "           1       0.08      0.11      0.09       115\n",
      "\n",
      "    accuracy                           0.95      4929\n",
      "   macro avg       0.53      0.54      0.53      4929\n",
      "weighted avg       0.96      0.95      0.95      4929\n",
      "\n",
      "AUC Score: 0.6101\n",
      "Running SHAP on Stage 75% ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [df0_FFF, df25_FFF, df50_FFF, df75_FFF]\n",
    "stage_list = [0, 25, 50, 75]\n",
    "\n",
    "base_model_name = \"LightGBM_DDD\"\n",
    "classification_mode = \"dropout\"\n",
    "\n",
    "\n",
    "for df, stage in zip(df_list, stage_list):\n",
    "   \n",
    "    model_path = f\"D:/myx/Data science project·/outputs/models/{base_model_name}_{stage}_change/{classification_mode}/lgb_model.pkl\"\n",
    "    print(f\"\\n\\nTesting {base_model_name}_{stage} on Course F\")\n",
    "\n",
    "    test_model_on_unseen(\n",
    "        model_path=model_path,\n",
    "        df_list=[df],         \n",
    "        stage_list=[stage],   \n",
    "        classification_mode=classification_mode\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88969d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Testing LightGBM_DDD_0 on Course F \n",
      "\n",
      " Testing on Stage 0% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54      2168\n",
      "           1       0.68      0.56      0.61      3215\n",
      "\n",
      "    accuracy                           0.58      5383\n",
      "   macro avg       0.58      0.59      0.58      5383\n",
      "weighted avg       0.60      0.58      0.58      5383\n",
      "\n",
      "AUC Score: 0.6038\n",
      "Running SHAP on Stage 0% ...\n",
      "\n",
      "\n",
      " Testing LightGBM_DDD_25 on Course F \n",
      "\n",
      " Testing on Stage 25% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      2215\n",
      "           1       0.76      0.78      0.77      3396\n",
      "\n",
      "    accuracy                           0.72      5611\n",
      "   macro avg       0.70      0.70      0.70      5611\n",
      "weighted avg       0.72      0.72      0.72      5611\n",
      "\n",
      "AUC Score: 0.7716\n",
      "Running SHAP on Stage 25% ...\n",
      "\n",
      "\n",
      " Testing LightGBM_DDD_50 on Course F \n",
      "\n",
      " Testing on Stage 50% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68      1841\n",
      "           1       0.83      0.79      0.81      3398\n",
      "\n",
      "    accuracy                           0.76      5239\n",
      "   macro avg       0.74      0.75      0.75      5239\n",
      "weighted avg       0.77      0.76      0.77      5239\n",
      "\n",
      "AUC Score: 0.8280\n",
      "Running SHAP on Stage 50% ...\n",
      "\n",
      "\n",
      " Testing LightGBM_DDD_75 on Course F \n",
      "\n",
      " Testing on Stage 75% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.70      1531\n",
      "           1       0.89      0.81      0.85      3398\n",
      "\n",
      "    accuracy                           0.80      4929\n",
      "   macro avg       0.77      0.79      0.78      4929\n",
      "weighted avg       0.81      0.80      0.80      4929\n",
      "\n",
      "AUC Score: 0.8783\n",
      "Running SHAP on Stage 75% ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = [df0_FFF, df25_FFF, df50_FFF, df75_FFF]\n",
    "stage_list = [0, 25, 50, 75]\n",
    "\n",
    "base_model_name = \"LightGBM_DDD\"\n",
    "classification_mode = \"pass_fail\"\n",
    "\n",
    "\n",
    "for df, stage in zip(df_list, stage_list):\n",
    "   \n",
    "    model_path = f\"D:/myx/Data science project·/outputs/models/{base_model_name}_{stage}_change/{classification_mode}/lgb_model.pkl\"\n",
    "    print(f\"\\n\\n Testing {base_model_name}_{stage} on Course F \")\n",
    "\n",
    "    test_model_on_unseen(\n",
    "        model_path=model_path,\n",
    "        df_list=[df],          \n",
    "        stage_list=[stage],   \n",
    "        classification_mode=classification_mode\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
